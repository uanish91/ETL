{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOujAg4yfg9sM8TIBl+6jT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uanish91/ETL/blob/main/ETL_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Build a News ETL Data Pipeline Using Python and SQLite**"
      ],
      "metadata": {
        "id": "wxYBfIpUlc5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import the Libraries and Connect to NewsAPI"
      ],
      "metadata": {
        "id": "f6lZ3U6ZlPQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APw5JM9pkwSf",
        "outputId": "afbcfba8-ddb0-4b66-afd5-e3f83de7a2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newsapi-python\n",
            "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from newsapi-python) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2024.2.2)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.7\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sqlite3 as sql\n",
        "!pip install newsapi-python\n",
        "from newsapi import NewsApiClient\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use news-api python library\n",
        "#Get your API key by heading over to NEWS API registration page\n",
        "news_api_key = \"5bba0ebc778d42b2a040d45d25187f00\"\n",
        "news_api = NewsApiClient(api_key = news_api_key)"
      ],
      "metadata": {
        "id": "vhj4wGGdmBXV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Retrieve and print News Articles"
      ],
      "metadata": {
        "id": "BCPx6dcbrWgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The news_api pulls json file with sections status, total_results and articles\n",
        "#Define a function to extract the articles related tp AI.\n",
        "def extract_news_data():\n",
        "  try:\n",
        "    result = news_api.get_everything(q = 'AI', language = 'en', sort_by='publishedAt')\n",
        "    logging.info(\"Connection is successful\")\n",
        "    return result[\"articles\"]\n",
        "  except:\n",
        "      logging.error(\"Connection is unsuccessful\")\n",
        "      return None\n",
        "\n",
        "articles = extract_news_data()\n",
        "print(articles[:5])\n",
        "\n",
        "\n",
        "#ItemIterate over the list for getting the keys - Optional\n",
        "seen_keys = set()\n",
        "for item in articles:\n",
        "    # Iterate over each key in the dictionary\n",
        "    for key in item.keys():\n",
        "        # Split the key on underscore (_) if it contains one, otherwise use the key as is\n",
        "        first_word = key.split(\":\")[0]\n",
        "        if first_word not in seen_keys:\n",
        "          print(first_word)\n",
        "          seen_keys.add(first_word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4DAo7V0m3Zr",
        "outputId": "a7d081a0-b2b2-4701-a95f-de6ac341081b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'source': {'id': None, 'name': 'Samsung.com'}, 'author': 'Samsung Newsroom', 'title': 'Samsung Showcases Innovative AI TV Technologies at 2024 Southeast Asia Tech Seminar', 'description': 'Samsung to meet with media and industry professionals to share company’s AI-enhanced lineup of Neo QLED 8K, OLED and lifestyle products and discuss latest industry trends', 'url': 'https://news.samsung.com/global/samsung-showcases-innovative-ai-tv-technologies-at-2024-southeast-asia-tech-seminar', 'urlToImage': 'https://img.global.news.samsung.com/global/wp-content/uploads/2024/04/SEA-Tech-Seminar-2024_thumb728.jpg', 'publishedAt': '2024-04-24T02:51:54Z', 'content': 'Samsung Electronics, the worlds leading TV manufacturer for the 18th consecutive year, commenced its 2024 Southeast Asia Tech Seminar in Bangkok, Thailand. From April 23 to 24, Samsung will showcase … [+3213 chars]'}, {'source': {'id': None, 'name': 'Wccftech'}, 'author': 'Rohail Saleem', 'title': 'Elon Musk Says That Tesla’s AI Training Capacity Will Be Equivalent to Around 85,000 Units of NVIDIA’s H100 Chips by the End of 2024', 'description': \"Tesla's AI training compute capacity increased by 130 percent in Q1 2024 alone. However, if Elon Musk's ambitions pan out, this capacity is heading for a nearly 500 percent increase through 2024. This is not accurate. Tesla would be second highest and X/xAI w…\", 'url': 'https://wccftech.com/elon-musk-says-that-tesla-ai-training-capacity-will-be-equivalent-to-around-85000-units-of-nvidias-h100-chips-by-the-end-of-2024/', 'urlToImage': 'https://cdn.wccftech.com/wp-content/uploads/2024/04/Tesla-3.jpg', 'publishedAt': '2024-04-24T02:45:15Z', 'content': \"This is not investment advice. The author has no position in any of the stocks mentioned. Wccftech.com has a disclosure and ethics policy.\\r\\nTesla's AI training compute capacity increased by 130 perce… [+2575 chars]\"}, {'source': {'id': None, 'name': 'The Star Online'}, 'author': 'HO JIA WEN', 'title': 'International system on brink of collapse, says Amnesty report', 'description': 'PETALING JAYA: Amnesty International has released its State of the World’s Human Rights Report 2023/24, which highlighted numerous violations from conflicts globally, especially between Palestine and Israel. Read full story', 'url': 'https://www.thestar.com.my/news/nation/2024/04/24/international-system-on-brink-of-collapse-says-amnesty-report', 'urlToImage': 'https://apicms.thestar.com.my/uploads/images/2024/04/24/2659077.jpg', 'publishedAt': '2024-04-24T02:45:00Z', 'content': 'PETALING JAYA: Amnesty International has released its State of the Worlds Human Rights Report 2023/24, which highlighted numerous violations from conflicts globally, especially between Palestine and … [+1939 chars]'}, {'source': {'id': None, 'name': 'Techpowerup.com'}, 'author': 'btarunr', 'title': 'Samsung Signs $3 Billion HBM3E 12H Supply Deal with AMD', 'description': 'Korean media reports that Samsung Electronics has signed a 4.134 trillion Won ($3 billion) agreement with AMD to supply 12-high HBM3E stacks. AMD uses HBM stacks in its AI and HPC accelerators based on its CDNA architecture. This deal is significant, as it gi…', 'url': 'https://www.techpowerup.com/321835/samsung-signs-usd-3-billion-hbm3e-12h-supply-deal-with-amd', 'urlToImage': 'https://www.techpowerup.com/img/3EIuG5bum5UgAOXr.jpg', 'publishedAt': '2024-04-24T02:41:20Z', 'content': 'Korean media reports that Samsung Electronics has signed a 4.134 trillion Won ($3 billion) agreement with AMD to supply 12-high HBM3E stacks. AMD uses HBM stacks in its AI and HPC accelerators based … [+1061 chars]'}, {'source': {'id': None, 'name': 'Thepinknews.com'}, 'author': 'Gabriella Ferlita', 'title': 'First look at Jennifer Lopez taking down AI Simu Liu in the trailer for Netflix’s ATLAS', 'description': 'The full-length trailer for Jennifer Lopez’s upcoming film ATLAS has dropped, and it shows the “Jenny from the Block” hitmaker taking down an AI bot, played by Simu Liu.\\xa0 Throughout her impressive filmography, Lopez has embodied all sorts of characters, inclu…', 'url': 'https://www.thepinknews.com/2024/04/24/atlas-jennifer-lopez/', 'urlToImage': 'https://www.thepinknews.com/wp-content/uploads/2024/04/Untitled-design-2024-04-24T123131.250.png', 'publishedAt': '2024-04-24T02:38:51Z', 'content': 'The full-length trailer for Jennifer Lopezs upcoming film ATLAS has dropped, and it shows the “Jenny from the Block” hitmaker taking down an AI bot, played by Simu Liu.\\xa0\\r\\nThroughout her impressive fi… [+1786 chars]'}]\n",
            "source\n",
            "author\n",
            "title\n",
            "description\n",
            "url\n",
            "urlToImage\n",
            "publishedAt\n",
            "content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  3. Clean Author Column"
      ],
      "metadata": {
        "id": "FULKbv6b0z5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define a function to format the authors name into title case\n",
        "#Split the name at comma and make first name title cased\n",
        "def clean_author_column(text):\n",
        "  try:\n",
        "    return text.split(\",\")[0].title()\n",
        "  except AttributeError:\n",
        "    return \"No Author\"\n"
      ],
      "metadata": {
        "id": "-4mLOlnltHkI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Transform News Data"
      ],
      "metadata": {
        "id": "bj_0cYhc0o5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the transform stage from ETL\n",
        "#The extracted data has to be transformed to be further loaded into a dataframe for processing in staging area.\n",
        "#Replace the value for source key with name's key\n",
        "def transform_news_data(articles):\n",
        "  article_list = []\n",
        "  for i in articles:\n",
        "    article_list.append([value.get(\"name\",0) if key == \"source\"\n",
        "                         else\n",
        "                         value for key, value in i.items() if key in [\"author\", \"title\", \"publishedAt\", \"content\", \"url\", \"source\"]])\n",
        "    #Convert the dictionary into dataframe\n",
        "    df = pd.DataFrame(article_list, columns = [\"source\", \"Author Name\", \"News Title\", \"URL\", \"Date Published\", \"Content\"])\n",
        "    #change the format of date published column\n",
        "    df[\"Date Published\"] = pd.to_datetime(df[\"Date Published\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    #Apply the function to title case the author column\n",
        "    df[\"Author Name\"] = df[\"Author Name\"].apply(clean_author_column)\n",
        "    return df\n",
        "\n",
        "transformed_data = transform_news_data(articles)\n",
        "print(transformed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXyB5yFR4lwB",
        "outputId": "72ebe587-d762-4994-cf12-e92629081577"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           source Author Name  \\\n",
            "0  MobiHealthNews   No Author   \n",
            "\n",
            "                                          News Title  \\\n",
            "0  GE HealthCare partners with Elekta for radiati...   \n",
            "\n",
            "                                                 URL       Date Published  \\\n",
            "0  https://www.mobihealthnews.com/news/ge-healthc...  2024-04-23 17:25:13   \n",
            "\n",
            "                                             Content  \n",
            "0  GE HealthCare has partnered with radiation the...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Load the Data into SQLite DB"
      ],
      "metadata": {
        "id": "6euqOsJv4dDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data into the sql database.\n",
        "#Define load_news_data to load the processed data into sql database\n",
        "def load_news_data(data):\n",
        "  #Use sqlite3.connect() to establish a connection with sqlite3 database\n",
        "  #Name the table as news_table.db\n",
        "  with sql.connect('news_table.db') as connection:\n",
        "    #Establish a cursor object to execute queries\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS news_table(\n",
        "      'source' VARCHAR (30),\n",
        "      'Author Name' TEXT,\n",
        "      'News Title' TEXT,\n",
        "      'URL' TEXT,\n",
        "      'Date Published' TEXT,\n",
        "      'Content' TEXT)''')\n",
        "  data.to_sql(name= \"news_table\", con = connection, index = False, if_exists = \"append\")\n",
        "\n",
        "result = load_news_data(transformed_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "VKdGJBcsQGec"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5a. Check if the data is loaded into sqlite database (Optional)"
      ],
      "metadata": {
        "id": "oYgjJz0_Q5U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if the data is loaded(Optional)\n",
        "def check_data_loaded():\n",
        "  with sql.connect('news_table.db') as connection:\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(\"SELECT * FROM news_table\")\n",
        "    rows = cursor.fetchall()\n",
        "    for row in rows:\n",
        "      print(row)\n",
        "\n",
        "print(check_data_loaded())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUhgRsaF0QUo",
        "outputId": "f6067c45-70c3-4e4d-d342-2ec18b942479"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Theinventory.com', 'The Inventory Bot', 'Leadaybetter 2 HEPA + 4 Foam & Felt Filters for Shark Navigator Lift-Away NV350, Now 15% Off', 'https://theinventory.com/leadaybetter-2-hepa-4-foam-felt-filters-for-shark-n-1851428897', '2024-04-23 16:37:04', \"Whether you're looking to simply replace your shark Navigator Lift-Away NV350, NV351, NV352 series vacuum cleaner filters or seeking to optimize your vacuum's efficiency, the Leadybetter 2 HEPA + 4 F… [+1984 chars]\")\n",
            "('MobiHealthNews', 'No Author', 'GE HealthCare partners with Elekta for radiation therapy', 'https://www.mobihealthnews.com/news/ge-healthcare-partners-elekta-radiation-therapy', '2024-04-23 17:25:13', 'GE HealthCare has partnered with radiation therapy company Elekta to develop new software to improve clinicians experience and enable greater precision treatment.\\xa0\\r\\nElekta will use GE HealthCares MIM… [+2256 chars]')\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Automate the steps with Apache Airflow by Initializing the DAG object."
      ],
      "metadata": {
        "id": "nok3gJBZW5UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install the apache-airflow in colab\n",
        "#!pip install --ignore-installed apache-airflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "awwEWHgC-i_P",
        "outputId": "d20735a2-749b-43fc-9d5d-ca34e0590265"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-airflow\n",
            "  Using cached apache_airflow-2.9.0-py3-none-any.whl (13.3 MB)\n",
            "Collecting alembic<2.0,>=1.13.1 (from apache-airflow)\n",
            "  Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "Collecting argcomplete>=1.10 (from apache-airflow)\n",
            "  Using cached argcomplete-3.3.0-py3-none-any.whl (42 kB)\n",
            "Collecting asgiref (from apache-airflow)\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting attrs>=22.1.0 (from apache-airflow)\n",
            "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "Collecting blinker>=1.6.2 (from apache-airflow)\n",
            "  Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting colorlog<5.0,>=4.0.2 (from apache-airflow)\n",
            "  Using cached colorlog-4.8.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting configupdater>=3.1.1 (from apache-airflow)\n",
            "  Using cached ConfigUpdater-3.2-py2.py3-none-any.whl (34 kB)\n",
            "Collecting connexion[flask]<3.0,>=2.10.0 (from apache-airflow)\n",
            "  Using cached connexion-2.14.2-py2.py3-none-any.whl (95 kB)\n",
            "Collecting cron-descriptor>=1.2.24 (from apache-airflow)\n",
            "  Using cached cron_descriptor-1.4.3-py3-none-any.whl (49 kB)\n",
            "Collecting croniter>=2.0.2 (from apache-airflow)\n",
            "  Using cached croniter-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Collecting cryptography>=39.0.0 (from apache-airflow)\n",
            "  Using cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "Collecting deprecated>=1.2.13 (from apache-airflow)\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dill>=0.2.2 (from apache-airflow)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Collecting flask-caching>=1.5.0 (from apache-airflow)\n",
            "  Using cached Flask_Caching-2.1.0-py3-none-any.whl (28 kB)\n",
            "Collecting flask-session<0.6,>=0.4.0 (from apache-airflow)\n",
            "  Using cached flask_session-0.5.0-py3-none-any.whl (7.2 kB)\n",
            "Collecting flask-wtf>=0.15 (from apache-airflow)\n",
            "  Using cached flask_wtf-1.2.1-py3-none-any.whl (12 kB)\n",
            "Collecting flask<2.3,>=2.2 (from apache-airflow)\n",
            "  Using cached Flask-2.2.5-py3-none-any.whl (101 kB)\n",
            "Collecting fsspec>=2023.10.0 (from apache-airflow)\n",
            "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "Collecting google-re2>=1.0 (from apache-airflow)\n",
            "  Using cached google_re2-1.1-6-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (516 kB)\n",
            "Collecting gunicorn>=20.1.0 (from apache-airflow)\n",
            "  Using cached gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
            "Collecting httpx (from apache-airflow)\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Collecting importlib_metadata>=6.5 (from apache-airflow)\n",
            "  Using cached importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting itsdangerous>=2.0 (from apache-airflow)\n",
            "  Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting jinja2>=3.0.0 (from apache-airflow)\n",
            "  Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Collecting jsonschema>=4.18.0 (from apache-airflow)\n",
            "  Using cached jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "Collecting lazy-object-proxy (from apache-airflow)\n",
            "  Using cached lazy_object_proxy-1.10.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68 kB)\n",
            "Collecting linkify-it-py>=2.0.0 (from apache-airflow)\n",
            "  Using cached linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting lockfile>=0.12.2 (from apache-airflow)\n",
            "  Using cached lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting markdown-it-py>=2.1.0 (from apache-airflow)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Collecting markupsafe>=1.1.1 (from apache-airflow)\n",
            "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting marshmallow-oneofschema>=2.0.1 (from apache-airflow)\n",
            "  Using cached marshmallow_oneofschema-3.1.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting mdit-py-plugins>=0.3.0 (from apache-airflow)\n",
            "  Using cached mdit_py_plugins-0.4.0-py3-none-any.whl (54 kB)\n",
            "Collecting opentelemetry-api>=1.15.0 (from apache-airflow)\n",
            "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "Collecting opentelemetry-exporter-otlp (from apache-airflow)\n",
            "  Using cached opentelemetry_exporter_otlp-1.24.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting packaging>=14.0 (from apache-airflow)\n",
            "  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
            "Collecting pathspec>=0.9.0 (from apache-airflow)\n",
            "  Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting pendulum<4.0,>=2.1.2 (from apache-airflow)\n",
            "  Using cached pendulum-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "Collecting pluggy>=1.0 (from apache-airflow)\n",
            "  Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
            "Collecting psutil>=4.2.0 (from apache-airflow)\n",
            "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "Collecting pygments>=2.0.1 (from apache-airflow)\n",
            "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "Collecting pyjwt>=2.0.0 (from apache-airflow)\n",
            "  Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting python-daemon>=3.0.0 (from apache-airflow)\n",
            "  Using cached python_daemon-3.0.1-py3-none-any.whl (31 kB)\n",
            "Collecting python-dateutil>=2.3 (from apache-airflow)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Collecting python-nvd3>=0.15.0 (from apache-airflow)\n",
            "  Using cached python_nvd3-0.16.0-py3-none-any.whl\n",
            "Collecting python-slugify>=5.0 (from apache-airflow)\n",
            "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting requests<3,>=2.27.0 (from apache-airflow)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Collecting rfc3339-validator>=0.1.4 (from apache-airflow)\n",
            "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting rich-argparse>=1.0.0 (from apache-airflow)\n",
            "  Using cached rich_argparse-1.4.0-py3-none-any.whl (19 kB)\n",
            "Collecting rich>=12.4.4 (from apache-airflow)\n",
            "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "Collecting setproctitle>=1.1.8 (from apache-airflow)\n",
            "  Using cached setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sqlalchemy<2.0,>=1.4.36 (from apache-airflow)\n",
            "  Using cached SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "Collecting sqlalchemy-jsonfield>=1.0 (from apache-airflow)\n",
            "  Using cached SQLAlchemy_JSONField-1.0.2-py3-none-any.whl (10 kB)\n",
            "Collecting tabulate>=0.7.5 (from apache-airflow)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting tenacity!=8.2.0,>=6.2.0 (from apache-airflow)\n",
            "  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Collecting termcolor>=1.1.0 (from apache-airflow)\n",
            "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Collecting unicodecsv>=0.14.1 (from apache-airflow)\n",
            "  Using cached unicodecsv-0.14.1-py3-none-any.whl\n",
            "Collecting universal-pathlib>=0.2.2 (from apache-airflow)\n",
            "  Using cached universal_pathlib-0.2.2-py3-none-any.whl (46 kB)\n",
            "Collecting werkzeug<3,>=2.0 (from apache-airflow)\n",
            "  Using cached werkzeug-2.3.8-py3-none-any.whl (242 kB)\n",
            "Collecting apache-airflow-providers-common-io (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_common_io-1.3.1-py3-none-any.whl (16 kB)\n",
            "Collecting apache-airflow-providers-common-sql (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_common_sql-1.12.0-py3-none-any.whl (45 kB)\n",
            "Collecting apache-airflow-providers-fab>=1.0.2 (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_fab-1.0.4-py3-none-any.whl (78 kB)\n",
            "Collecting apache-airflow-providers-ftp (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_ftp-3.8.0-py3-none-any.whl (19 kB)\n",
            "Collecting apache-airflow-providers-http (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_http-4.10.1-py3-none-any.whl (27 kB)\n",
            "Collecting apache-airflow-providers-imap (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_imap-3.5.0-py3-none-any.whl (17 kB)\n",
            "Collecting apache-airflow-providers-smtp (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_smtp-1.6.1-py3-none-any.whl (22 kB)\n",
            "Collecting apache-airflow-providers-sqlite (from apache-airflow)\n",
            "  Using cached apache_airflow_providers_sqlite-3.7.1-py3-none-any.whl (13 kB)\n",
            "Collecting Mako (from alembic<2.0,>=1.13.1->apache-airflow)\n",
            "  Using cached Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "Collecting typing-extensions>=4 (from alembic<2.0,>=1.13.1->apache-airflow)\n",
            "  Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
            "Collecting flask-appbuilder==4.4.1 (from apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached Flask_AppBuilder-4.4.1-py3-none-any.whl (2.2 MB)\n",
            "Collecting flask-login>=0.6.2 (from apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached Flask_Login-0.6.3-py3-none-any.whl (17 kB)\n",
            "Collecting apispec[yaml]<7,>=6.0.0 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached apispec-6.6.1-py3-none-any.whl (30 kB)\n",
            "Collecting colorama<1,>=0.3.9 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting click<9,>=8 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Collecting email-validator>=1.0.5 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting Flask-Babel<3,>=1 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached Flask_Babel-2.0.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting Flask-Limiter<4,>3 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached Flask_Limiter-3.6.0-py3-none-any.whl (28 kB)\n",
            "Collecting Flask-SQLAlchemy<3,>=2.4 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached Flask_SQLAlchemy-2.5.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting Flask-JWT-Extended<5.0.0,>=4.0.0 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached Flask_JWT_Extended-4.6.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting marshmallow<4,>=3.18.0 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "Collecting marshmallow-sqlalchemy<0.29.0,>=0.22.0 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached marshmallow_sqlalchemy-0.28.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting prison<1.0.0,>=0.2.1 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached prison-0.2.1-py2.py3-none-any.whl (5.8 kB)\n",
            "Collecting sqlalchemy-utils<1,>=0.32.21 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached SQLAlchemy_Utils-0.41.2-py3-none-any.whl (93 kB)\n",
            "Collecting WTForms<4 (from flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached wtforms-3.1.2-py3-none-any.whl (145 kB)\n",
            "Collecting clickclick<21,>=1.2 (from connexion[flask]<3.0,>=2.10.0->apache-airflow)\n",
            "  Using cached clickclick-20.10.2-py2.py3-none-any.whl (7.4 kB)\n",
            "Collecting PyYAML<7,>=5.1 (from connexion[flask]<3.0,>=2.10.0->apache-airflow)\n",
            "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "Collecting inflection<0.6,>=0.3.1 (from connexion[flask]<3.0,>=2.10.0->apache-airflow)\n",
            "  Using cached inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Collecting werkzeug<3,>=2.0 (from apache-airflow)\n",
            "  Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "Collecting pytz>2021.1 (from croniter>=2.0.2->apache-airflow)\n",
            "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "Collecting cffi>=1.12 (from cryptography>=39.0.0->apache-airflow)\n",
            "  Using cached cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.13->apache-airflow)\n",
            "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "Collecting cachelib<0.10.0,>=0.9.0 (from flask-caching>=1.5.0->apache-airflow)\n",
            "  Using cached cachelib-0.9.0-py3-none-any.whl (15 kB)\n",
            "Collecting zipp>=0.5 (from importlib_metadata>=6.5->apache-airflow)\n",
            "  Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->apache-airflow)\n",
            "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->apache-airflow)\n",
            "  Using cached referencing-0.35.0-py3-none-any.whl (26 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->apache-airflow)\n",
            "  Using cached rpds_py-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting uc-micro-py (from linkify-it-py>=2.0.0->apache-airflow)\n",
            "  Using cached uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.1.0->apache-airflow)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting importlib_metadata>=6.5 (from apache-airflow)\n",
            "  Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting tzdata>=2020.1 (from pendulum<4.0,>=2.1.2->apache-airflow)\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "Collecting time-machine>=2.6.0 (from pendulum<4.0,>=2.1.2->apache-airflow)\n",
            "  Using cached time_machine-2.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
            "Collecting docutils (from python-daemon>=3.0.0->apache-airflow)\n",
            "  Using cached docutils-0.21.2-py3-none-any.whl (587 kB)\n",
            "Collecting setuptools>=62.4.0 (from python-daemon>=3.0.0->apache-airflow)\n",
            "  Using cached setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.3->apache-airflow)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify>=5.0->apache-airflow)\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.27.0->apache-airflow)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.27.0->apache-airflow)\n",
            "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27.0->apache-airflow)\n",
            "  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.27.0->apache-airflow)\n",
            "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy<2.0,>=1.4.36->apache-airflow)\n",
            "  Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
            "Collecting more-itertools>=9.0.0 (from apache-airflow-providers-common-sql->apache-airflow)\n",
            "  Using cached more_itertools-10.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting sqlparse>=0.4.2 (from apache-airflow-providers-common-sql->apache-airflow)\n",
            "  Using cached sqlparse-0.5.0-py3-none-any.whl (43 kB)\n",
            "Collecting aiohttp>=3.9.2 (from apache-airflow-providers-http->apache-airflow)\n",
            "  Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting requests_toolbelt (from apache-airflow-providers-http->apache-airflow)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Collecting anyio (from httpx->apache-airflow)\n",
            "  Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
            "Collecting httpcore==1.* (from httpx->apache-airflow)\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Collecting sniffio (from httpx->apache-airflow)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->apache-airflow)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc==1.24.0 (from opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.24.0 (from opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
            "Collecting grpcio<2.0.0,>=1.0.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "Collecting opentelemetry-sdk~=1.24.0 (from opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "Collecting protobuf<5.0,>=3.19 (from opentelemetry-proto==1.24.0->opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp>=3.9.2->apache-airflow-providers-http->apache-airflow)\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp>=3.9.2->apache-airflow-providers-http->apache-airflow)\n",
            "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.9.2->apache-airflow-providers-http->apache-airflow)\n",
            "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.9.2->apache-airflow-providers-http->apache-airflow)\n",
            "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp>=3.9.2->apache-airflow-providers-http->apache-airflow)\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting pycparser (from cffi>=1.12->cryptography>=39.0.0->apache-airflow)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Collecting exceptiongroup>=1.0.2 (from anyio->httpx->apache-airflow)\n",
            "  Using cached exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=1.0.5->flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "Collecting Babel>=2.3 (from Flask-Babel<3,>=1->flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
            "Collecting limits>=2.8 (from Flask-Limiter<4,>3->flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached limits-3.11.0-py3-none-any.whl (45 kB)\n",
            "Collecting ordered-set<5,>4 (from Flask-Limiter<4,>3->flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-sdk~=1.24.0->opentelemetry-exporter-otlp-proto-grpc==1.24.0->opentelemetry-exporter-otlp->apache-airflow)\n",
            "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting importlib-resources>=1.3 (from limits>=2.8->Flask-Limiter<4,>3->flask-appbuilder==4.4.1->apache-airflow-providers-fab>=1.0.2->apache-airflow)\n",
            "  Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Installing collected packages: unicodecsv, text-unidecode, pytz, lockfile, cron-descriptor, colorlog, zipp, wrapt, urllib3, uc-micro-py, tzdata, typing-extensions, termcolor, tenacity, tabulate, sqlparse, sniffio, six, setuptools, setproctitle, rpds-py, PyYAML, python-slugify, pyjwt, pygments, pycparser, psutil, protobuf, pluggy, pathspec, packaging, ordered-set, opentelemetry-semantic-conventions, multidict, more-itertools, mdurl, markupsafe, lazy-object-proxy, itsdangerous, inflection, importlib-resources, idna, h11, grpcio, greenlet, google-re2, fsspec, frozenlist, exceptiongroup, docutils, dnspython, dill, configupdater, colorama, click, charset-normalizer, certifi, cachelib, blinker, Babel, attrs, async-timeout, argcomplete, yarl, WTForms, werkzeug, universal-pathlib, sqlalchemy, rfc3339-validator, requests, referencing, python-dateutil, python-daemon, prison, opentelemetry-proto, marshmallow, markdown-it-py, Mako, linkify-it-py, jinja2, importlib_metadata, httpcore, gunicorn, googleapis-common-protos, email-validator, deprecated, clickclick, cffi, asgiref, apispec, anyio, aiosignal, time-machine, sqlalchemy-utils, sqlalchemy-jsonfield, rich, requests_toolbelt, python-nvd3, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, mdit-py-plugins, marshmallow-sqlalchemy, marshmallow-oneofschema, limits, jsonschema-specifications, httpx, flask, cryptography, croniter, alembic, aiohttp, rich-argparse, pendulum, opentelemetry-sdk, jsonschema, flask-wtf, Flask-SQLAlchemy, flask-session, flask-login, Flask-Limiter, Flask-JWT-Extended, flask-caching, Flask-Babel, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, flask-appbuilder, connexion, opentelemetry-exporter-otlp, apache-airflow-providers-common-sql, apache-airflow-providers-sqlite, apache-airflow-providers-smtp, apache-airflow-providers-imap, apache-airflow-providers-http, apache-airflow-providers-ftp, apache-airflow-providers-fab, apache-airflow-providers-common-io, apache-airflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "sphinx 5.0.2 requires docutils<0.19,>=0.14, but you have docutils 0.21.2 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2024.3.1 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.52 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.3.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires wrapt<1.15,>=1.11.0, but you have wrapt 1.16.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Babel-2.14.0 Flask-Babel-2.0.0 Flask-JWT-Extended-4.6.0 Flask-Limiter-3.6.0 Flask-SQLAlchemy-2.5.1 Mako-1.3.3 PyYAML-6.0.1 WTForms-3.1.2 aiohttp-3.9.5 aiosignal-1.3.1 alembic-1.13.1 anyio-3.7.1 apache-airflow-2.9.0 apache-airflow-providers-common-io-1.3.1 apache-airflow-providers-common-sql-1.12.0 apache-airflow-providers-fab-1.0.4 apache-airflow-providers-ftp-3.8.0 apache-airflow-providers-http-4.10.1 apache-airflow-providers-imap-3.5.0 apache-airflow-providers-smtp-1.6.1 apache-airflow-providers-sqlite-3.7.1 apispec-6.6.1 argcomplete-3.3.0 asgiref-3.8.1 async-timeout-4.0.3 attrs-23.2.0 blinker-1.7.0 cachelib-0.9.0 certifi-2024.2.2 cffi-1.16.0 charset-normalizer-3.3.2 click-8.1.7 clickclick-20.10.2 colorama-0.4.6 colorlog-4.8.0 configupdater-3.2 connexion-2.14.2 cron-descriptor-1.4.3 croniter-2.0.5 cryptography-42.0.5 deprecated-1.2.14 dill-0.3.8 dnspython-2.6.1 docutils-0.18.1 email-validator-2.1.1 exceptiongroup-1.2.1 flask-2.2.5 flask-appbuilder-4.4.1 flask-caching-2.1.0 flask-login-0.6.3 flask-session-0.5.0 flask-wtf-1.2.1 frozenlist-1.4.1 fsspec-2023.6.0 google-re2-1.1 googleapis-common-protos-1.63.0 greenlet-3.0.3 grpcio-1.62.2 gunicorn-22.0.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 importlib-resources-6.4.0 importlib_metadata-7.0.0 inflection-0.5.1 itsdangerous-2.2.0 jinja2-3.1.3 jsonschema-4.19.2 jsonschema-specifications-2023.12.1 lazy-object-proxy-1.10.0 limits-3.11.0 linkify-it-py-2.0.3 lockfile-0.12.2 markdown-it-py-3.0.0 markupsafe-2.1.5 marshmallow-3.21.1 marshmallow-oneofschema-3.1.1 marshmallow-sqlalchemy-0.28.2 mdit-py-plugins-0.4.0 mdurl-0.1.2 more-itertools-10.1.0 multidict-6.0.5 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 ordered-set-4.1.0 packaging-24.0 pathspec-0.12.1 pendulum-3.0.0 pluggy-1.4.0 prison-0.2.1 protobuf-3.20.3 psutil-5.9.5 pycparser-2.22 pygments-2.16.1 pyjwt-2.8.0 python-daemon-3.0.1 python-dateutil-2.8.2 python-nvd3-0.16.0 python-slugify-8.0.4 pytz-2023.4 referencing-0.34.0 requests-2.31.0 requests_toolbelt-1.0.0 rfc3339-validator-0.1.4 rich-13.7.1 rich-argparse-1.4.0 rpds-py-0.18.0 setproctitle-1.3.3 setuptools-67.7.2 six-1.16.0 sniffio-1.3.1 sqlalchemy-1.4.52 sqlalchemy-jsonfield-1.0.2 sqlalchemy-utils-0.41.2 sqlparse-0.5.0 tabulate-0.9.0 tenacity-8.2.3 termcolor-2.4.0 text-unidecode-1.3 time-machine-2.14.1 typing-extensions-4.11.0 tzdata-2024.1 uc-micro-py-1.0.3 unicodecsv-0.14.1 universal-pathlib-0.2.2 urllib3-2.0.7 werkzeug-2.2.3 wrapt-1.14.1 yarl-1.9.4 zipp-3.18.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "_re2",
                  "_time_machine",
                  "certifi",
                  "cffi",
                  "charset_normalizer",
                  "colorlog",
                  "dateutil",
                  "deprecated",
                  "dill",
                  "google",
                  "greenlet",
                  "importlib_metadata",
                  "jinja2",
                  "lazy_object_proxy",
                  "markupsafe",
                  "pkg_resources",
                  "pluggy",
                  "psutil",
                  "pygments",
                  "re2",
                  "requests",
                  "setuptools",
                  "six",
                  "sqlalchemy",
                  "sqlalchemy_jsonfield",
                  "tabulate",
                  "time_machine",
                  "wrapt",
                  "yaml",
                  "zipp"
                ]
              },
              "id": "d92cb90ee70f49a6b2512ff693e4f428"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!airflow db init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2w-ElNT_E3X",
        "outputId": "c8be7c31-43c3-476e-972d-363ba7701658"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DB: sqlite:////root/airflow/airflow.db\n",
            "[\u001b[34m2024-04-24T17:26:03.402+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m216} INFO\u001b[0m - Context impl \u001b[01mSQLiteImpl\u001b[22m.\u001b[0m\n",
            "[\u001b[34m2024-04-24T17:26:03.403+0000\u001b[0m] {\u001b[34mmigration.py:\u001b[0m219} INFO\u001b[0m - Will assume \u001b[01mnon-transactional\u001b[22m DDL.\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Running stamp_revision  -> 1949afb29106\n",
            "WARNI [airflow.models.crypto] empty cryptography key - values will not be stored encrypted.\n",
            "Initialization done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import airflow"
      ],
      "metadata": {
        "id": "RONrDhuo9OoJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ensure the executables are present in the path environement used by colab.\n",
        "#Add the path where dependencies are installed.\n",
        "import sys\n",
        "print(sys.version)\n",
        "print(sys.executable)\n",
        "print(sys.path)\n",
        "sys.path.append('/usr/bin/python3')\n",
        "sys.path.append('/usr/local/lib/python3.10')\n",
        "print(sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-XgYpKg669w",
        "outputId": "be6efe34-81ea-4692-9efe-e43392ec0c70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "/usr/bin/python3\n",
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython', '/root/airflow/dags', '/root/airflow/config', '/root/airflow/plugins']\n",
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython', '/root/airflow/dags', '/root/airflow/config', '/root/airflow/plugins', '/usr/bin/python3', '/usr/local/lib/python3.10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import DAG, datetime and timedelta\n",
        "from airflow import DAG\n",
        "from datetime import datetime, timedelta, time\n",
        "from airflow.operators.python import PythonOperator"
      ],
      "metadata": {
        "id": "ew7lmqRHK7zN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables for scheduling the DAG\n",
        "to_date = datetime.now().date()\n",
        "from_date = to_date - timedelta(days=1)"
      ],
      "metadata": {
        "id": "XFd7Nw4RO4rx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize DAG object\n",
        "dag= DAG(dag_id=\"news_etl\", default_args = {'start_date':datetime.combine(from_date, time(0,0)), 'retries':1}, schedule = 'daily',)"
      ],
      "metadata": {
        "id": "y2z1ZylgbiRI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace the extract_news_data() function to make it comaptible with Airflow\n",
        "def extract_news_data(**kwargs):\n",
        "    try:\n",
        "        result = news_api.get_everything(q=\"AI\", language=\"en\", from_param=from_date, to=to_date)\n",
        "        logging.info(\"Connection is successful.\")\n",
        "        # Push the result to the XCom\n",
        "        kwargs['task_instance'].xcom_push(key='extract_result', value=result[\"articles\"])\n",
        "    except:\n",
        "        logging.error(\"Connection is unsuccessful.\")\n",
        ""
      ],
      "metadata": {
        "id": "9ZYGyeXbdYj8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace the transform_news_data() function to make it comaptible with Xcoms within a DAG\n",
        "def transform_news_data(**kwargs):\n",
        "    article_list = []\n",
        "    # Add the XCom pull logic to pull data from the XCom\n",
        "    data = kwargs['task_instance'].xcom_pull(task_ids='extract_news', key='extract_result')\n",
        "\n",
        "    # Logging message after the XCom pull\n",
        "    logging.info(\"Data pulled successfully\")\n",
        "\n",
        "    for i in data:\n",
        "        article_list.append([value.get(\"name\", 0) if key == \"source\" else value for key, value in i.items() if key in [\"author\", \"title\", \"publishedAt\", \"content\", \"url\", \"source\"]])\n",
        "\n",
        "    df = pd.DataFrame(article_list, columns=[\"Source\", \"Author Name\", \"News Title\", \"URL\", \"Date Published\", \"Content\"])\n",
        "\n",
        "    df[\"Date Published\"] = pd.to_datetime(df[\"Date Published\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    df[\"Author Name\"] = df[\"Author Name\"].apply(clean_author_column)\n",
        "\n",
        "    #Add the XCom push logic to push data to the XCom\n",
        "    kwargs['task_instance'].xcom_push(key='transform_df', value=df.to_json())\n",
        "    logging.info(\"Transformed data pushed to XCom successfully.\")\n"
      ],
      "metadata": {
        "id": "wGGB5v7qOLmG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace the load_news_data() function to make it comaptible with Xcoms within a DAG\n",
        "def load_news_data(**kwargs):\n",
        "  with sql.connect('news_table.db') as connection:\n",
        "        # Create a cursor within the context manager\n",
        "        cursor = connection.cursor()\n",
        "\n",
        "        # Create a table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS news_table (\n",
        "                \"Source\" VARCHAR(30),\n",
        "                \"Author Name\" TEXT,\n",
        "                \"News Title\" TEXT,\n",
        "                \"URL\" TEXT,\n",
        "                \"Date Published\" TEXT,\n",
        "                \"Content\" TEXT\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Pull data from XCom\n",
        "        data = kwargs['task_instance'].xcom_pull(task_ids='transform_news', key='transform_df')\n",
        "\n",
        "        # Convert data into a DataFrame\n",
        "        df = pd.read_json(data)\n",
        "\n",
        "        # Logging message before loading data\n",
        "        logging.info(\"Ready to load data into the database.\")\n",
        "\n",
        "        df.to_sql(name=\"news_table\", con=connection, index=False, if_exists=\"append\")\n",
        "\n",
        "        # Logging message after loading data\n",
        "        logging.info(\"Data successfully loaded into the database.\")"
      ],
      "metadata": {
        "id": "eiCKsZUNOVtV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Python operators\n",
        "_extract_news_data = PythonOperator(\n",
        "    task_id = \"extract_news\",\n",
        "    python_callable = extract_news_data,\n",
        "    provide_context = True,\n",
        "    dag = dag\n",
        ")\n",
        "\n",
        "_transform_news_data = PythonOperator(\n",
        "    task_id = \"transform_news\",\n",
        "    python_callable = transform_news_data,\n",
        "    provide_context = True,\n",
        "    dag = dag\n",
        ")\n",
        "\n",
        "_load_news_data = PythonOperator(\n",
        "    task_id = \"load_news\",\n",
        "    python_callable = load_news_data,\n",
        "    provide_context = True,\n",
        "    dag = dag\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "rkoQy0fiOnsv",
        "outputId": "fab4d1e1-9ac2-4918-f399-dc96945f9be7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;33m<\u001b[0m\u001b[1;33mipython-input-\u001b[0m\u001b[1;33m29\u001b[0m\u001b[1;33m-36ccdc6e7614\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m2\u001b[0m\u001b[1;33m RemovedInAirflow3Warning\u001b[0m\u001b[33m: provide_context is deprecated as of \u001b[0m\u001b[1;33m2.0\u001b[0m\u001b[33m and is no longer required\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;ipython-input-</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">29</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">-36ccdc6e7614&gt;:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> RemovedInAirflow3Warning</span><span style=\"color: #808000; text-decoration-color: #808000\">: provide_context is deprecated as of </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2.0</span><span style=\"color: #808000; text-decoration-color: #808000\"> and is no longer required</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;33m<\u001b[0m\u001b[1;33mipython-input-\u001b[0m\u001b[1;33m29\u001b[0m\u001b[1;33m-36ccdc6e7614\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m9\u001b[0m\u001b[1;33m RemovedInAirflow3Warning\u001b[0m\u001b[33m: provide_context is deprecated as of \u001b[0m\u001b[1;33m2.0\u001b[0m\u001b[33m and is no longer required\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;ipython-input-</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">29</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">-36ccdc6e7614&gt;:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">9</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> RemovedInAirflow3Warning</span><span style=\"color: #808000; text-decoration-color: #808000\">: provide_context is deprecated as of </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2.0</span><span style=\"color: #808000; text-decoration-color: #808000\"> and is no longer required</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;33m<\u001b[0m\u001b[1;33mipython-input-\u001b[0m\u001b[1;33m29\u001b[0m\u001b[1;33m-36ccdc6e7614\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m16\u001b[0m\u001b[1;33m RemovedInAirflow3Warning\u001b[0m\u001b[33m: provide_context is deprecated as of \u001b[0m\u001b[1;33m2.0\u001b[0m\u001b[33m and is no longer required\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">&lt;ipython-input-</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">29</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">-36ccdc6e7614&gt;:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">16</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> RemovedInAirflow3Warning</span><span style=\"color: #808000; text-decoration-color: #808000\">: provide_context is deprecated as of </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2.0</span><span style=\"color: #808000; text-decoration-color: #808000\"> and is no longer required</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dependencies\n",
        "_extract_news_data >> _transform_news_data >> _load_news_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3RH1mu7QjGA",
        "outputId": "5418ae31-3d3c-451d-c251-2e36b36d30a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Task(PythonOperator): load_news>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with sql.connect(\"news_table.db\") as connection:\n",
        "    df = pd.read_sql(\"SELECT * FROM news_table;\", connection)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "vIIjbLySQod4",
        "outputId": "0ea9226c-61a0-477d-db32-7a85356158e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             source        Author Name  \\\n",
              "0  Theinventory.com  The Inventory Bot   \n",
              "1    MobiHealthNews          No Author   \n",
              "\n",
              "                                          News Title  \\\n",
              "0  Leadaybetter 2 HEPA + 4 Foam & Felt Filters fo...   \n",
              "1  GE HealthCare partners with Elekta for radiati...   \n",
              "\n",
              "                                                 URL       Date Published  \\\n",
              "0  https://theinventory.com/leadaybetter-2-hepa-4...  2024-04-23 16:37:04   \n",
              "1  https://www.mobihealthnews.com/news/ge-healthc...  2024-04-23 17:25:13   \n",
              "\n",
              "                                             Content  \n",
              "0  Whether you're looking to simply replace your ...  \n",
              "1  GE HealthCare has partnered with radiation the...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f95cead1-75e9-48bb-ade0-166999e5e4d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>Author Name</th>\n",
              "      <th>News Title</th>\n",
              "      <th>URL</th>\n",
              "      <th>Date Published</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Theinventory.com</td>\n",
              "      <td>The Inventory Bot</td>\n",
              "      <td>Leadaybetter 2 HEPA + 4 Foam &amp; Felt Filters fo...</td>\n",
              "      <td>https://theinventory.com/leadaybetter-2-hepa-4...</td>\n",
              "      <td>2024-04-23 16:37:04</td>\n",
              "      <td>Whether you're looking to simply replace your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MobiHealthNews</td>\n",
              "      <td>No Author</td>\n",
              "      <td>GE HealthCare partners with Elekta for radiati...</td>\n",
              "      <td>https://www.mobihealthnews.com/news/ge-healthc...</td>\n",
              "      <td>2024-04-23 17:25:13</td>\n",
              "      <td>GE HealthCare has partnered with radiation the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f95cead1-75e9-48bb-ade0-166999e5e4d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f95cead1-75e9-48bb-ade0-166999e5e4d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f95cead1-75e9-48bb-ade0-166999e5e4d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34b8daf0-a3c4-4783-9dcf-b29f0edb7b4b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34b8daf0-a3c4-4783-9dcf-b29f0edb7b4b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34b8daf0-a3c4-4783-9dcf-b29f0edb7b4b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"MobiHealthNews\",\n          \"Theinventory.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Author Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No Author\",\n          \"The Inventory Bot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"News Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"GE HealthCare partners with Elekta for radiation therapy\",\n          \"Leadaybetter 2 HEPA + 4 Foam & Felt Filters for Shark Navigator Lift-Away NV350, Now 15% Off\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"https://www.mobihealthnews.com/news/ge-healthcare-partners-elekta-radiation-therapy\",\n          \"https://theinventory.com/leadaybetter-2-hepa-4-foam-felt-filters-for-shark-n-1851428897\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date Published\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2024-04-23 17:25:13\",\n          \"2024-04-23 16:37:04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"GE HealthCare has partnered with radiation therapy company Elekta to develop new software to improve clinicians experience and enable greater precision treatment.\\u00a0\\r\\nElekta will use GE HealthCares MIM\\u2026 [+2256 chars]\",\n          \"Whether you're looking to simply replace your shark Navigator Lift-Away NV350, NV351, NV352 series vacuum cleaner filters or seeking to optimize your vacuum's efficiency, the Leadybetter 2 HEPA + 4 F\\u2026 [+1984 chars]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byRp1JL4Qts0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}